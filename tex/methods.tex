\section{Methods}

Each tag was represented as an ordered, fixed-length bitstring,
\begin{align*}
t = \langle t_0, t_1, t_2, \dots, t_{n-2}, t_{n-1} \rangle
\end{align*}
where
\begin{align*}
\forall i, t_i \in \{0, 1\}.
\end{align*}
In all experiments, we used 32 bit tags.

For consistency between metrics, we bound all metrics between 0 and 1.

\subsection{Integer Metric}

This metric is inspired by \citep{spector2011tag}.
They used positive integers between 0 and 100 to name referents.
Queries were provided the referent that had the next-larger value, wrapping around from 100 back to 0.

In this metric, we compare tags according to their value as an unsigned integer according to the following representation $f$,
\begin{align*}
f(t)
= \sum_{i=0}^{n-1} t_i \times 2^i.
\end{align*}

The distance metric $I$ between two length-$n$ tags $t$ and $u$ is
\begin{align*}
I(t, u) =
\begin{cases}
  \frac{2^n - f(t) + f(u)}{2^n}, & \text{if } f(t) > f(u), \\
  \frac{f(t) - f(u)}{2^n},         & \text{else} f(t) \leq f(u).
\end{cases}
\end{align*}

Note that this metric is non-commutative, i.e., it is not necessarily true that $I(t, u) = I(u, t)$.

Note also that this metric is one-dimensional.

A algorithmic advantage of this metric is that it allows for log-time matching.

\subsection{Hamming Metric}

This metric is based on the work of \citep{lalejini2019else}, originally after TODO hamming cite(?).

In this metric, we compare tags according to their bitwise hamming distance.
Mathematically speaking for tags $t$ and $u$ we compute the distance according to the metric $M$ as,
\begin{align*}
M(t, u)
= \frac{
  \#\{ i : t_i \neq u_i, i=0, \dots ,n-1\}
}{
  n
}
\end{align*}

This metric is commutative and $n$-dimensional.

\subsection{Hash Metric}

This metric is original to the our paper and meant to serve as a control.

The an arbitrary, but determinsitic value, uniformly distributed between 0 and 1.

We rely on the \texttt{hash\_combine} function, adapted from BOOST (TODO cite).

for two values \texttt{v1} and \texttt{v2}, \texttt{hash\_combine} is defined as follows
\begin{verbatim}
unsigned int hash_combine(
  unsigned int v1,
  unsigned int v2
) {
  return v1 ^ (
    v2 * 0x9e3779b9
    + (v1 << 6) + (v1 >> 2)
  );
}
\end{verbatim}

We compute the hash value of a tag as follows
\begin{verbatim}
unsigned int h(unsigned char *tag) {
  unsigned int result = tag[0];
  for (int i = 1; i < 4; ++i){
    result = hash_combine(result, t[i]);
  }
  return result;
}
\end{verbatim}
where \texttt{tag} is the tag's bitstring stored as an array of bytes.

To compute the metric $H$ we then call \texttt{hash\_combine} to combine the hash values of the tags $t$ and $u$
\begin{align*}
H(t, u) = \texttt{hash\_combine( h(}t\texttt{), h(}u\texttt{))}
\end{align*}

Note that this is not commutative.

\subsection{Streak Metric}

This metric was originally proposed by \citep{downing2015intelligence}.
Downing claims that it exhibits
It is computed according to the ratio between the longest contiguously matching substring among two bitsets and the longest contiguously mismatching substring among those two bitsets.
Downing claims that this metric exhibits greater robustness compared to integer and hamming distance metrics using mutational walk experiments but does not demonstrate it in an evolving system.

We define the greatest contiguously-matching length of $n$-long bitstrings $t$ and $u$ as follows,
\begin{align*}
m(t, u) = \max(\{i - j \forall i, j \in 0..n-1 \mid \forall q \in i..j, t_q = u_q \})
\end{align*}

We define the greatest contiguously-mismatching length as follows,
\begin{align*}
n(t, u) = \max(\{i - j \forall i, j \in 0..n-1 \mid \forall q \in i..j, t_q \neq u_q \})
\end{align*}

The streak metric $S'$  with tags $t$ and $u$
\begin{align*}
S'(t, u)
= \frac{ p(n(t,u)) }{p(m(t,u)) + p(n(t,u))}.
\end{align*}
where $p$ approximates the probability of a contiguously-matching substring between

It is worth noting that the formula for computing the probability of a $k$-bit match or mismatch, given by Downing as follows, is actually mathematically flawed.
\begin{align*}
p_k
= \frac{n - k + 1}{2^k}
\end{align*}

The probability of a $0$-bit match according to this formula would be computed as $p_0 = \frac{n - 0 + 1}{2^0} = n + 1$ which is clearly impossible because $p_0 > 1 \forall n > 0$.
The actual can probability be achieved using a lookup table computed using dynamic programming.

However, the formula Downing presented provides a useful approximation to the probability of a $k$ bit match.
For computational efficiency and consistency with the existing literature we use clamp edge cases between 0 and 1 to yield the corrected streak metric $S$.

\begin{align*}
S(t, u) =
\max( \min( S'(t, u), 1), 0)
\end{align*}

\subsection{Selection Techniques}

best with threshold \citep{lalejini2019else}

roulette
\begin{itemize}
\item skew
\item similarity cut-off
\end{itemize}

evolvable (per-tag) threshold

\subsection{Evolutionary Characteristics}

find citations for this subsection in my undergraduate thesis

\begin{itemize}
  \item Question: do tag matches evolve to become more specific? i.e., become stronger over time?
        If so, do matches lock-in early, leading to strong historical contingencies?
  \item Question: How stable are tag-based references over time? Are stable references
        associated with successful lineages? Does stability change over time (e.g.,
        low stability early, increasingly higher stability over time? W/major stability
        shake-ups when new architectures arise)
  \item Do tags enable more complex genetic architectures over traditional reference
        techniques?
  \item Quantify how often perturbations (mutations) change references. Compare
        successful lineages to general population averages (are successful lineages
        avoiding or embracing perturbation)
  \item Track the frequency of and effect of (deleterious, neutral, beneficial)
        perturbations that change references. Again, are successful lineages different
        from population averages?
\end{itemize}

\subsubsection{Duplication and Differentiation}

\begin{itemize}
  \item Question: How fast and complicated can duplication/divergence events occur?
        Quantify how often these events occur in general vs how often they are along
        successful lineages.
\end{itemize}

\subsubsection{Canalization}

Question:
\begin{itemize}
\item several sets of ``related" signal/response groups... triggering the wrong signal/response pair within the group is okay... but triggering the signal/response pairs that correspond to different groups is not okay
\item do we end up with mutations tending to cause changes that stay within the group? how much mutation until we start to see signal/response pairs from different groups triggered
\item (side question) how strong of an effect can plasticity have on promoting canalization (e.g., select for plastic rearrangement of connections within group)
\end{itemize}

\subsubsection{Plasticity (via regulation)}

Question: how fast/how complicated can we evolve plastic responses (e.g., in environment A certain signal/response pairs; in environment B certain signal/response pairs) using regulation

maybe also differentiation?
(e.g., go stably into state A or state B based on an initial environmental cue)

\subsubsection{Bandwidth}

Question: what is the relationship between the number of signals/responses and the evolutionary difficulty of
\begin{itemize}
\item evolving n connection pairs de-novo
\item with n connection pairs evolved, evolving a n+1 connection pair
\end{itemize}

\subsubsection{Hidden Genetic Variation}

Question: evolve one signal/response pair (might need multiple signal/response pairs), how much tag diversity exists in population at end of run?

\subsubsection{Degeneracy}

Question: how many independent but redundant cue/response tag pairs (that link the same cue and same response) arise spontaneously?

\subsubsection{Robustness}

\begin{itemize}
\item plot match score versus random mutational walk like in Downing
\item fat-tailed or thin-tailed? (e.g., gradual or walking off a cliff)
\end{itemize}

distribution of effect on match score for different mutations
\begin{itemize}
\item are some mutations silent?
\item do some mutations cause extreme/catastrophic effects?
\item e.g., how often do perturbations disrupt existing references?
\end{itemize}

\subsection{System-level Metrics}

systems:
\begin{itemize}
\item environment matching with SignalGP
\item DISHTINY with SignalGP
\item lawnmower \citep{spector2011tag} / dirt-sensing, obstacle-avoiding robot \citep{spector2011tag} / even-4-parity \citep{spector2012tag}
\item TODO more / better please
\end{itemize}

metrics:
\begin{itemize}
\item evolvability signatures \citep{tarapore2015evolvability}
\item solution quality
\item phenotypic lock-in
\item the graph structure of gene regulatory networks that tend to evolve?
\end{itemize}

\subsection{Computational Efficiency}

\begin{itemize}
\item time to calculate distance between two tags
\item the computational complexity of selection techniques
\item possible optimizations that make matching better than linear?
(not with regulation, I suspect)
\end{itemize}

\subsection{Applications}

\begin{itemize}
  \item GP Modules (SignalGP, Lee's PushGP stuff)
  \item Memory access in GP: use tags to label and refer to locations in memory.
        Tags should allow us to evolve the \textit{size} of our memory buffer. Perhaps
        this is useful?
  \item Neural networks: could use tags to specify (and evolve) connections between
        nodes and to specify node functions (e.g., 0000 = sin, 1111 = threshold, etc)
  \item Genetic alphabet: use tag-based referencing to implement an indirect encoding.
        e.g., each instruction/operator has a tag id, start codons?
\end{itemize}

\subsubsection{SignalGP Tag Extensions}

\begin{itemize}
  \item Module regulation
  \item Allow modules to be renamed by `renaming' instructions (another form of
        module regulation). This is sort of similar to Lee's PushGP implementation
        that allows Push programs to label and subsequently relabel tagged things.
\end{itemize}

\subsection{Implementation}

We implemented our experimental system using the Empirical library for scientific software development in C++, available at \url{https://github.com/devosoft/Empirical}.
The code used to perform and analyze our experiments, our figures, data from our experiments, and a live in-browser demo of our system is available via the Open Science Framework at \url{https://osf.io/TODO/}.
